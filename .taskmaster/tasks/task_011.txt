# Task ID: 11
# Title: Build Core Chat API Endpoint with Streaming
# Status: in-progress
# Dependencies: 2
# Priority: high
# Description: Create the main `/api/chat` endpoint to handle user messages, interact with the LLM, and stream responses back to the client using Mastra AI framework. Since we're using Vite + React architecture, implement an Express backend server with the chat endpoint, or alternatively use a client-side approach with direct LLM API calls.
# Details:
For the Vite + React architecture, implement one of two approaches: (1) Create a separate Express backend server that hosts the `/api/chat` endpoint, handles CORS for the Vite frontend, and manages the Mastra AI framework server-side, or (2) Implement a client-side solution using Mastra AI directly from the React frontend if the framework supports browser environments. The backend approach is recommended for better security and API key management. Use the Mastra AI framework to create an IFS therapy agent with built-in tool management capabilities. Mastra provides a robust agent framework that will support future integration of session management, part discovery, and evidence tracking tools. Start with a basic IFS chat agent implementation using the agent's base system prompt and Mastra's agent configuration. Initially, messages will be processed without full session management - session tools will be added incrementally in later tasks. Focus on establishing the core streaming infrastructure using Mastra's streaming capabilities and IFS agent personality/capabilities. The Mastra agent will be configured to prepare for future tool integration including logEvidence, findPatterns, and session management functions. If using Express backend, ensure proper WebSocket or Server-Sent Events setup for streaming responses to the Vite frontend.

# Test Strategy:
Create an integration test that sends a message to the endpoint and verifies that a streaming response is received. For backend approach: test the Express server endpoint directly and verify CORS headers. For client-side approach: mock the Mastra AI calls and test the React component's handling of streaming responses. Use Mastra's testing utilities to mock the LLM and test the agent's behavior independently. Test the IFS agent's base prompt and response patterns through Mastra's agent configuration. Verify that the Mastra agent is properly initialized and can handle basic conversations. Initially skip JWT validation and session persistence tests - these will be added when session management tools are integrated. Test that the agent framework is ready to accept tool additions in future tasks. Use Vitest for unit tests and consider MSW (Mock Service Worker) for mocking API calls in the frontend tests.
