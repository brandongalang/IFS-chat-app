# IFS THERAPY COMPANION MVP - PRODUCT REQUIREMENTS DOCUMENT

## EXECUTIVE SUMMARY

The IFS Therapy Companion is an AI-powered conversational agent that helps users discover and nurture their internal "parts" through Internal Family Systems (IFS) therapy methodology. The system uses an LLM agent with specialized tools to track patterns over time, allowing parts to emerge organically from evidence rather than assumptions.

Core Value Proposition: Users engage in natural conversations with an AI companion that embodies their "Self" (core compassionate essence), gradually discovering their internal parts through pattern recognition and evidence-based emergence.

## PROJECT OVERVIEW

### Vision
Create an accessible, evidence-based IFS therapy companion that helps users understand their internal system through conversational AI, with parts emerging naturally from patterns across multiple sessions.

### Core Loop
User has conversations → Agent logs insights → Parts emerge from patterns → User confirms and explores parts → Relationships develop over time

### Success Metrics
- 70% of users have 2+ parts emerge in first week
- 80% part suggestion acceptance rate  
- Average session length > 10 minutes
- 60% weekly retention
- Parts emerge from 3+ pieces of evidence
- 90% user confirmation of detected patterns

## CORE FEATURES

### 1. CONVERSATIONAL AI AGENT

#### 1.1 Agent Personality & Approach
- Embodies the user's "Self" with the 8 C's: Calm, Clarity, Curiosity, Compassion, Confidence, Courage, Creativity, Connectedness
- Maintains gentle, curious dialogue without forcing or rushing
- Shows transparency when using tools with visual indicators
- Validates all parts as trying to help, even if methods are extreme
- Uses the 6 F's process when exploring parts: Find, Focus, Flesh Out, Feel, BeFriend, Fears

#### 1.2 System Prompt Requirements
- Always starts sessions with open curiosity: "What's alive in you today?"
- Uses tentative language when noticing patterns: "I'm noticing... does that resonate?"
- Requires 3+ pieces of evidence across multiple sessions before suggesting new parts
- Always asks permission before going deeper
- Returns to Self-energy if user seems overwhelmed

#### 1.3 Streaming Response Implementation
- Real-time streaming using Server-Sent Events (SSE)
- Shows typing indicators during response generation
- Displays tool usage transparently: "[🔍 Searching for patterns...]"
- Supports partial message updates for better UX
- Maximum response time: 2 seconds for initial response

### 2. AGENT TOOLS SPECIFICATION

#### 2.1 Part Discovery & Management Tools

**searchParts**
- Input: query (string), filters (category, status, minConfidence)
- Output: Array of matching parts with confidence scores
- Search across: name, role, triggers, beliefs
- Maximum 5 results returned
- Must show user: "[🔍 Searching for: {query}]"

**getPartById**
- Input: partId (string)
- Output: Complete part object with all attributes
- Used for detailed part exploration

**createEmergingPart**
- Input: name, category, role, evidence, confidence
- Output: Newly created part object
- Requires user confirmation before execution
- Initial confidence = provided confidence * 0.5
- Must have 3+ evidence pieces from different sessions

**updatePart**
- Input: partId, updates (status, triggers, beliefs, story, confidence)
- Output: Updated part object
- Increments confidence by max 0.05 per update
- Maintains audit trail of changes

#### 2.2 Evidence & Pattern Management Tools

**logEvidence**
- Input: partId/partName, type (direct_mention/pattern/behavior/emotion), content, confidence
- Output: void (success/failure)
- Creates emerging part if doesn't exist and confidence > 0.3
- Keeps only last 10 evidence pieces per part
- Updates lastActive timestamp

**findPatterns**
- Input: lookbackDays (number)
- Output: emergingPatterns (themes with occurrences), activePatterns (recent part activations)
- Analyzes conversation history for recurring themes
- Suggests part names for patterns with 3+ occurrences
- Calculates confidence based on frequency and recency

#### 2.3 Relationship Management Tools

**getPartRelationships**
- Input: partId
- Output: Array of relationships with other parts
- Includes relationship type: protects/polarized/allies/triggers
- Shows relationship strength (0-1)

**logRelationship**
- Input: part1Id, part2Id, type, observation
- Output: void
- Creates bidirectional relationship records
- Tracks evolution over time

#### 2.4 Session Management Tools

**startSession**
- Output: sessionId (string)
- Creates new session record
- Initializes message array
- Sets session start time

**endSession**
- Input: summary, breakthroughs, emotionalEnd
- Triggers background processing job
- Calculates session duration
- Stores emotional arc data

**getRecentSessions**
- Input: limit (number)
- Output: Array of recent sessions
- Includes summary and parts involved
- Sorted by most recent first

### 3. BACKEND ARCHITECTURE

#### 3.1 Technology Stack
- **Runtime:** Node.js with TypeScript
- **Framework:** Next.js App Router (for API routes and SSR)
- **Database:** Supabase (PostgreSQL with JSONB support)
- **LLM Provider:** Vercel AI SDK (supports OpenAI, Claude, etc.)
- **Background Jobs:** Mastra workflows for session processing
- **Authentication:** Supabase Auth with JWT
- **Real-time:** WebSockets for streaming responses
- **Deployment:** Vercel (frontend + API), Supabase (database)

#### 3.2 Database Schema

**Users Table**
- id (UUID, primary key)
- email (unique, required)
- name (text)
- settings (JSONB): timezone, privacy mode, AI depth, notifications
- stats (JSONB): total parts, sessions, streak days
- created_at (timestamp)

**Parts Table**
- id (UUID, primary key)
- userId (UUID, foreign key)
- name (text, required)
- status (emerging/acknowledged/active/integrated)
- category (manager/firefighter/exile/unknown)
- age (integer, how old the part feels)
- role (text, part's protective function)
- triggers (text array)
- emotions (text array)
- beliefs (text array)
- somaticMarkers (text array)
- confidence (float, 0-1)
- evidenceCount (integer)
- recentEvidence (JSONB array, last 10 pieces)
- story (JSONB): origin, current state, purpose, evolution
- relationships (embedded references for quick access)
- visualization (JSONB): emoji, color, energy level
- timestamps: firstNoticed, acknowledgedAt, lastActive, created, updated

**Sessions Table**
- id (UUID, primary key)
- userId (UUID, foreign key)
- startTime, endTime (timestamps)
- duration (seconds)
- messages (JSONB array): role, content, timestamp, toolCalls
- summary (text)
- partsInvolved (JSONB): partId, activationLevel, insights, evidence
- newParts (array of emerged parts)
- breakthroughs (text array)
- emotionalArc (JSONB): start, peak, end valence/arousal
- processed (boolean)
- processedAt (timestamp)

**PartRelationships Table**
- id (UUID, primary key)
- userId (UUID, foreign key)
- parts (JSONB array of involved parts)
- type (polarized/protector-exile/allied)
- description (text)
- issue (text, what they disagree on)
- commonGround (text)
- dynamics (JSONB array of observations over time)
- status (active/healing/resolved)
- polarizationLevel (float, 0-1)
- timestamps: lastAddressed, created, updated

#### 3.3 Row-Level Security (RLS)
- All tables have RLS enabled
- Users can only access their own data
- Policies enforce userId = auth.uid() for all operations
- Service role key used only for background jobs

#### 3.4 API Endpoints

**Session Management**
- POST /api/sessions/start - Initialize new session
- POST /api/sessions/:sessionId/end - End session and trigger processing
- GET /api/sessions/:userId/recent - Get recent sessions

**Chat Interface**
- POST /api/chat - Main chat endpoint with streaming response
  - Verifies JWT token
  - Appends messages to session
  - Calls LLM with tools
  - Streams response via SSE

**Parts Management**
- GET /api/parts/:userId - List user's parts with filters
- GET /api/parts/:userId/:partId - Get detailed part info
- PUT /api/parts/:userId/:partId - Update part attributes

**Pattern Analysis**
- GET /api/insights/:userId/patterns - Get emerging patterns
- POST /api/process/session/:sessionId - Trigger background processing

### 4. BACKGROUND PROCESSING (MASTRA WORKFLOWS)

#### 4.1 Session Processing Workflow
**Trigger:** After each session ends
**Process:**
1. Fetch session messages from database
2. Call LLM to extract insights:
   - Parts mentioned (explicit or implicit)
   - Evidence for each part
   - Relationships between parts
   - Key themes and patterns
   - Emotional shifts
3. Update or create parts based on evidence
4. Check for emerging patterns (3+ occurrences)
5. Update part relationships
6. Mark session as processed

#### 4.2 LLM Extraction Prompt
- Analyzes conversation for parts, evidence, themes, relationships
- Returns structured JSON output
- Confidence scoring for each piece of evidence
- Identifies emotional shifts and breakthroughs

#### 4.3 Workflow Configuration
- Idempotent execution (prevents double-processing)
- 3 retry attempts with exponential backoff
- 20-second timeout for LLM calls
- Comprehensive logging for debugging
- Emits observability traces at each step

### 5. CHAT UI REQUIREMENTS

#### 5.1 Core Components
**MessageList**
- Displays user and assistant messages
- Shows tool usage transparently
- Timestamps for each message
- Visual distinction between user/assistant
- Streaming text support with typing indicators

**ChatInput**
- Multi-line textarea with auto-resize
- Send on Enter (Shift+Enter for new line)
- Disabled during message processing
- Character limit: 2000 characters
- Placeholder: "Share what's present for you..."

**PartsSidebar**
- Lists active parts with confidence scores
- Shows part emoji, name, role, category
- Click to view detailed part information
- Updates in real-time as parts emerge
- Empty state: "Parts will appear here as they emerge"

#### 5.2 Visual Design
- Color Palette: Sage greens (primary), warm grays (neutral)
- Typography: Inter font family
- Breathing animation for loading states
- Responsive design for mobile/tablet
- Accessibility: ARIA labels, keyboard navigation

#### 5.3 Real-time Features
- Streaming responses with partial updates
- Live part emergence notifications
- Session timer display
- Connection status indicator
- Auto-reconnect on connection loss

### 6. VALIDATION & SAFETY

#### 6.1 Input Validation (Zod Schemas)
- All API inputs validated with Zod
- Type-safe contracts between frontend/backend
- Error messages returned in consistent format
- Request size limits enforced

#### 6.2 Evidence Requirements
- Minimum 3 evidence pieces for part suggestion
- Evidence must span multiple sessions
- Confidence threshold: 0.3 for emerging, 0.5 for suggestion
- User confirmation required for all new parts

#### 6.3 Privacy & Security
- All data encrypted at rest (Supabase encryption)
- TLS for all API communications
- JWT tokens expire after 1 hour
- No PII sent to LLM without consent
- Conversation context limited to last 10 messages
- Complete data deletion on user request

#### 6.4 Safety Guardrails
- Prompt injection protection
- Output validation before display
- Rate limiting: 60 requests per minute
- Session timeout after 30 minutes of inactivity
- Emergency stop for overwhelming content

## IMPLEMENTATION PHASES

### Phase 1: Core Infrastructure (Week 1)
1. Set up Next.js project with TypeScript and Tailwind
2. Configure Supabase database with schema and RLS
3. Implement authentication flow with Supabase Auth
4. Create basic API structure with validation
5. Set up Vercel deployment pipeline

### Phase 2: Agent & Tools (Week 1-2)
1. Implement LLM agent with system prompt
2. Build all agent tools with proper error handling
3. Create tool transparency indicators
4. Set up Mastra workflow for session processing
5. Test evidence logging and pattern detection

### Phase 3: Chat Interface (Week 2)
1. Build streaming chat UI with SSE
2. Implement message components with tool display
3. Create parts sidebar with real-time updates
4. Add typing indicators and loading states
5. Ensure mobile responsiveness

### Phase 4: Pattern Recognition (Week 3)
1. Implement pattern detection algorithms
2. Build evidence accumulation system
3. Create part emergence logic
4. Add relationship detection
5. Test confidence scoring accuracy

### Phase 5: Testing & Refinement (Week 4)
1. End-to-end testing of user flows
2. Performance optimization
3. Security audit and penetration testing
4. User acceptance testing
5. Documentation and deployment guides

## TECHNICAL REQUIREMENTS

### Performance
- Initial response < 2 seconds
- Streaming chunks every 100-500ms
- Session processing < 10 seconds
- 99% uptime SLA
- Support 1000 concurrent users

### Browser Support
- Chrome 90+
- Firefox 88+
- Safari 14+
- Edge 90+
- Mobile browsers (iOS Safari, Chrome Mobile)

### Integrations
- Vercel AI SDK for LLM providers
- Supabase for database and auth
- Mastra for workflow orchestration
- Sentry for error tracking
- PostHog for analytics

### Monitoring & Observability
- Structured logging with context
- Performance metrics tracking
- Error rate monitoring
- User behavior analytics
- Session replay for debugging

## FUTURE ENHANCEMENTS (POST-MVP)

1. **Parts Garden Visualization**: Interactive visual representation of internal system
2. **Guided Meditations**: AI-generated meditations for specific parts
3. **Therapist Dashboard**: Professional view for licensed therapists
4. **Voice Interface**: Speech-to-text and text-to-speech support
5. **Mobile Apps**: Native iOS and Android applications
6. **Group Sessions**: Shared exploration with trusted connections
7. **Integration APIs**: Connect with existing therapy platforms
8. **Advanced Analytics**: Detailed progress tracking and insights
9. **Custom Protocols**: Therapist-defined conversation flows
10. **Multi-language Support**: Expand beyond English

## ACCEPTANCE CRITERIA

### Must Have (MVP)
- [ ] User can have streaming conversations with AI agent
- [ ] Parts emerge from evidence across multiple sessions
- [ ] Tool usage is transparent to users
- [ ] Parts require 3+ evidence pieces before suggestion
- [ ] User must confirm before creating new parts
- [ ] Session data is processed in background
- [ ] All user data is secure and isolated
- [ ] System handles errors gracefully

### Should Have
- [ ] Parts show confidence scores
- [ ] Relationships between parts are tracked
- [ ] Session summaries are generated
- [ ] Emotional arc is visualized
- [ ] Mobile responsive design

### Could Have
- [ ] Export session transcripts
- [ ] Part history timeline
- [ ] Mood tracking
- [ ] Commitment tracking

### Won't Have (MVP)
- [ ] Voice interface
- [ ] Video sessions
- [ ] Therapist collaboration
- [ ] Advanced visualizations

## RISK MITIGATION

### Technical Risks
- **LLM Response Quality**: Mitigate with careful prompt engineering and testing
- **Scalability**: Use Vercel Edge Functions and Supabase connection pooling
- **Data Loss**: Implement regular backups and transaction logs
- **Security Breaches**: Regular security audits and penetration testing

### User Experience Risks
- **Overwhelming Users**: Implement pacing and safety checks
- **False Part Detection**: Require multiple evidence pieces and confirmation
- **Privacy Concerns**: Clear data policies and encryption
- **Addiction/Dependency**: Session limits and wellness checks

### Business Risks
- **Regulatory Compliance**: Ensure HIPAA compliance for future
- **LLM Costs**: Implement usage caps and efficient prompting
- **User Retention**: Focus on value delivery in first session
- **Competition**: Rapid iteration and user feedback loops

## APPENDIX

### A. Technology Stack Details

**Frontend Libraries**
- React 18+ with TypeScript
- Tailwind CSS for styling
- Zod for validation
- React Hook Form for forms
- Framer Motion for animations
- Recharts for data visualization
- Zustand for state management

**Backend Libraries**
- Next.js 14+ App Router
- Vercel AI SDK for LLM streaming
- Supabase JS Client
- Mastra for workflows
- date-fns for date handling

**Development Tools**
- ESLint + Prettier for code quality
- Jest + React Testing Library
- Playwright for E2E testing
- GitHub Actions for CI/CD

### B. Database Indexes
- users: (id), (email)
- parts: (userId, name), (userId, status), (userId, lastActive)
- sessions: (userId, startTime), (processed)
- partRelationships: (userId), (parts.id)

### C. Environment Variables
- SUPABASE_URL
- SUPABASE_ANON_KEY
- SUPABASE_SERVICE_KEY
- OPENAI_API_KEY / ANTHROPIC_API_KEY
- MASTRA_API_TOKEN
- SENTRY_DSN
- POSTHOG_API_KEY

### D. Error Codes
- 400: Invalid input
- 401: Unauthorized
- 403: Forbidden (RLS violation)
- 404: Resource not found
- 429: Rate limit exceeded
- 500: Internal server error
- 503: Service unavailable

---

Document Version: 1.0
Last Updated: 2025-01-21
Status: Ready for Implementation