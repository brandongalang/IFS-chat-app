# AI & Agentic Architecture

This document outlines the architectural vision for the Constellation AI, including its foundational principles and technical design.

## Foundational Principles

Our AI is not just a feature; it is the core of the product. Its design is guided by four foundational principles.

1.  **Human-AI Collaboration, Not Replacement:** The AI's role is that of a skilled companion, not an automated therapist. It **proposes**, and the **human disposes**. Every insight generated by the AI must be validated by the user. To enforce this, the AI is designed to use uncertainty language ("It seems like...", "I notice a pattern that might suggest...") and always defers to the user's wisdom as the ultimate source of truth. This principle is key to building user trust and agency.

2.  **Context-Aware Intelligence:** The AI's guidance must be hyper-personalized. This is achieved by maintaining a living `UserContextSummary` for each user. This object synthesizes all journaling, check-ins, confirmed parts, relationships, and past feedback. It is passed into the model with every interaction, ensuring that the AI's responses are grounded in the user's unique history and evolving internal landscape.

3.  **Evidence-Based Transparency:** To avoid the "black box" problem common in AI, every hypothesis the AI generates must be traceable and explainable. Each suggestion (e.g., the existence of a part, a relationship between two parts) is linked directly to the specific user language that triggered it. This is presented to the user with a confidence score, allowing them to audit the AI's reasoning and build trust through transparency.

4.  **Ethical Safeguards:** Working with one's internal world can be intense. The AI has a built-in responsibility to create a safe container for this work. This is implemented via a `DistressClassifier` that monitors user language for patterns of overwhelm or significant distress. If a high level of distress is detected, the system triggers a "Self-Check Pause," interrupting the flow to ask: *"I sense a lot of intensity here. On a scale of 1-10, how much access do you have to your Self-energy right now?"* The conversation only proceeds once the user confirms they are in a stable state.

## The `UserContextSummary`

This data object is the "brain" of the AI's personalization. It is a dynamically generated summary of the user's entire history, structured for optimal use by an LLM. A simplified representation might look like this:

```json
{
  "userName": "Brandon",
  "confirmedParts": [
    { "name": "The Critic", "role": "Tries to prevent failure by judging harshly.", "status": "active" },
    { "name": "Perfectionist", "role": "Believes perfect work will lead to safety.", "status": "active" }
  ],
  "confirmedRelationships": [
    { "parts": ["The Critic", "Perfectionist"], "type": "polarized", "issue": "Critic attacks when Perfectionist feels it's falling short." }
  ],
  "recentSessionThemes": ["Anxiety about work presentation", "Frustration with procrastination"],
  "userOverrides": ["User rejected 'Anxious part' suggestion on 2025-08-28"]
}
```

## Technical Architecture Vision

The AI system is envisioned as a multi-stage processing pipeline designed to optimize for safety, accuracy, and latency.

```python
class ConstellationAI:
    """
    This class represents the central AI engine that processes user interactions.
    """
    def __init__(self):
        # A fine-tuned Large Language Model specialized in identifying
        # language patterns indicative of IFS parts from user text.
        self.part_detector = FineTunedLLM("ifs-part-detection")

        # A Graph Neural Network (GNN) is ideal for this task because a user's
        # psyche is a graph of interconnected parts. A GNN can learn to infer
        # relationships (e.g., polarization, alliances) based on the attributes
        # of the parts and their co-occurrence in user text.
        self.relationship_mapper = GraphNeuralNetwork()

        # A simple, fast classifier trained to detect linguistic markers of
        # psychological distress (e.g., hopelessness, panic). Safety is the first gate.
        self.safety_monitor = DistressClassifier()

        # An ensemble model that combines signals from the part detector,
        # relationship mapper, and user history to produce a final confidence
        # score for any given hypothesis.
        self.confidence_scorer = EnsembleModel()

    def process_session(self, user_input, context: UserContextSummary):
        # Safety First: The first check is always for user distress.
        # If distress is high, we pause and engage a safety protocol.
        if self.safety_monitor.detect_distress(user_input) > 0.7:
            return self.generate_safety_pause()

        # Stage 1: Identify potential parts in the user's input, using
        # the existing context to avoid re-identifying known parts.
        parts = self.part_detector.identify_with_evidence(user_input, context)

        # Stage 2: Infer the relationships between the newly identified parts
        # and the existing parts from the user's context.
        relationships = self.relationship_mapper.infer_connections(parts, context.existing_parts)

        # Stage 3: Score the confidence of the generated hypotheses (new parts
        # and new relationships) based on the strength of the evidence and historical data.
        scored_output = self.confidence_scorer.evaluate(parts, relationships, context.user_history)

        # Stage 4: Format the output into a user-facing response, using
        # uncertainty language and providing links back to the evidence.
        return self.format_response(scored_output)
```

## Privacy-First Data Architecture

To build the necessary trust for such a sensitive application, the data architecture must be privacy-first by design.

-   **Client-Side Encryption:** All sensitive psychological data (journal entries, part profiles, etc.) must be encrypted on the client (browser/mobile app) with a key that only the user controls. This means that the raw, unencrypted data is never stored on our servers, protecting it even in the event of a server-side breach.
-   **Local Processing:** To minimize data transmission, lightweight models (like the `DistressClassifier` or simple pattern matchers) should run directly on the user's device when possible. Only more complex analyses that require larger models should be sent to the server.
-   **Federated Learning (Future Goal):** To improve our global models without compromising individual privacy, we will explore using federated learning techniques. This allows us to train models on user data across the network while that data remains on-device, sending only anonymized model updates back to the central server.
-   **Export Sovereignty:** The user is the ultimate owner of their psychological graph. They must have the ability to export their complete, decrypted data at any time in a machine-readable format. This ensures they are never locked into our platform.
